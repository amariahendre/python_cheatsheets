{"cells":[{"source":"# Pandas Cheatsheet","metadata":{},"id":"6282f101-3e05-495e-b871-cc8ab8ed39d7","cell_type":"markdown"},{"source":"import pandas as pd","metadata":{"executionTime":43,"lastSuccessfullyExecutedCode":"import pandas as pd"},"id":"fbaf7781-b6fd-4e39-8731-697080156169","cell_type":"code","execution_count":37,"outputs":[]},{"source":"## Pandas series","metadata":{},"id":"43ff671a-7a39-4acd-a3fc-e38b6ea01efb","cell_type":"markdown"},{"source":"import pandas as pd\n\ns = pd.Series([1, 2, 3, 4, 5])\nt = pd.Series([\"Angel\", \"MIX\", \"sky\"])\n\n# Accessing elements by index\ns[0]   # Returns the first element\ns[1:3] # Returns a new Series with elements 1 and 2\n\n# Accessing elements by label\ns = pd.Series([1, 2, 3, 4, 5], index=['a', 'b', 'c', 'd', 'e'])\ns['a']    # Returns the element with label 'a'\ns[['a', 'c', 'e']]  # Returns a new Series with elements 'a', 'c', and 'e'\n\n# Arithmetic operations\ns + 10   # Adds 10 to each element of s\ns * 2    # Multiplies each element of s by 2\ns / 2    # Divides each element of s by 2\n\n# Boolean operations\ns > 3    # Returns a new Series of boolean values indicating whether each element is greater than 3\ns[s > 3] # Returns a new Series with only the elements greater than 3\n\ns.sum()    # Returns the sum of all elements in s\ns.mean()   # Returns the mean of all elements in s\ns.median() # Returns the median of all elements in s\ns.min()    # Returns the minimum element in s\ns.max()    # Returns the maximum element in s\ns.std()    # Returns the standard deviation of all elements in s\n\nt.str.lower()     # Returns a new Series with all string elements converted to lowercase\nt.str.upper()     # Returns a new Series with all string elements converted to uppercase\nt.str.len()       # Returns a new Series with the length of each string element\nt.str.contains('a') # Returns a new Series of boolean values indicating whether each string element contains the letter 'a'\n\ns.isna()    # Returns a new Series of boolean values indicating whether each element is missing (NaN)\ns.dropna()  # Returns a new Series with all missing elements removed\ns.fillna(0) # Returns a new Series with all missing elements filled with 0","metadata":{"executionTime":33,"lastSuccessfullyExecutedCode":"import pandas as pd\n\ns = pd.Series([1, 2, 3, 4, 5])\nt = pd.Series([\"Angel\", \"MIX\", \"sky\"])\n\n# Accessing elements by index\ns[0]   # Returns the first element\ns[1:3] # Returns a new Series with elements 1 and 2\n\n# Accessing elements by label\ns = pd.Series([1, 2, 3, 4, 5], index=['a', 'b', 'c', 'd', 'e'])\ns['a']    # Returns the element with label 'a'\ns[['a', 'c', 'e']]  # Returns a new Series with elements 'a', 'c', and 'e'\n\n# Arithmetic operations\ns + 10   # Adds 10 to each element of s\ns * 2    # Multiplies each element of s by 2\ns / 2    # Divides each element of s by 2\n\n# Boolean operations\ns > 3    # Returns a new Series of boolean values indicating whether each element is greater than 3\ns[s > 3] # Returns a new Series with only the elements greater than 3\n\ns.sum()    # Returns the sum of all elements in s\ns.mean()   # Returns the mean of all elements in s\ns.median() # Returns the median of all elements in s\ns.min()    # Returns the minimum element in s\ns.max()    # Returns the maximum element in s\ns.std()    # Returns the standard deviation of all elements in s\n\nt.str.lower()     # Returns a new Series with all string elements converted to lowercase\nt.str.upper()     # Returns a new Series with all string elements converted to uppercase\nt.str.len()       # Returns a new Series with the length of each string element\nt.str.contains('a') # Returns a new Series of boolean values indicating whether each string element contains the letter 'a'\n\ns.isna()    # Returns a new Series of boolean values indicating whether each element is missing (NaN)\ns.dropna()  # Returns a new Series with all missing elements removed\ns.fillna(0) # Returns a new Series with all missing elements filled with 0"},"id":"7e31224e-1d15-4670-8e38-d9d13fe0f2e7","cell_type":"code","execution_count":38,"outputs":[]},{"source":"## From series to dataframe","metadata":{},"id":"21c6ea4c-3f03-41f0-a833-4e3e5835264b","cell_type":"markdown"},{"source":"# Make a Series of different foods\nfoods = pd.Series([\"Almond butter\", \"Eggs\", \"Avocado\"])\n\n# Make a Series of different dollar values \nprices = pd.Series([9, 6, 2])\n\n# Combine your Series of foods and dollar values into a DataFrame\nfood_data = pd.DataFrame({\"Foods\": foods,\n                          \"Price\": prices})\n\nfood_data.set_index(\"Foods\")","metadata":{"executionTime":41,"lastSuccessfullyExecutedCode":"# Make a Series of different foods\nfoods = pd.Series([\"Almond butter\", \"Eggs\", \"Avocado\"])\n\n# Make a Series of different dollar values \nprices = pd.Series([9, 6, 2])\n\n# Combine your Series of foods and dollar values into a DataFrame\nfood_data = pd.DataFrame({\"Foods\": foods,\n                          \"Price\": prices})\n\nfood_data.set_index(\"Foods\")"},"id":"ff4995ee-9838-4bdf-a571-27fe8fc0bc23","cell_type":"code","execution_count":39,"outputs":[]},{"source":"## Reading data","metadata":{},"id":"9f5e2de1-9713-484e-af83-ee24453e1ac6","cell_type":"markdown"},{"source":"df = pd.read_csv('filename.csv', index_col=0) # read CSV file\ndf = pd.read_excel('filename.xlsx', index_col=0) # read Excel file\n#df = pd.read_sql('query', connection) # read data from SQL database","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"executionTime":61,"lastSuccessfullyExecutedCode":"df = pd.read_csv('filename.csv', index_col=0) # read CSV file\ndf = pd.read_excel('filename.xlsx', index_col=0) # read Excel file\n#df = pd.read_sql('query', connection) # read data from SQL database"},"id":"08152c64-8eb9-467c-97fd-cac239174b2c","cell_type":"code","execution_count":40,"outputs":[]},{"source":"## Basic operations","metadata":{},"id":"2551e8d2-b600-40c9-a4e1-db631e43607a","cell_type":"markdown"},{"source":"df.head(10) # show first n rows of DataFrame\ndf.tail(10) # show last n rows of DataFrame\ndf.shape # get number of rows and columns\ndf.columns # get column names\ndf.index # get row index\ndf.info() # get information about DataFrame\ndf.describe() # get summary statistics for numeric columns\ndf.sort_values('duration_ms', ascending=True) # sort DataFrame by column\ndf.drop('duration_ms', axis=1) # remove a column\ndf.drop_duplicates() # remove duplicate rows","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"executionTime":358,"lastSuccessfullyExecutedCode":"df.head(10) # show first n rows of DataFrame\ndf.tail(10) # show last n rows of DataFrame\ndf.shape # get number of rows and columns\ndf.columns # get column names\ndf.index # get row index\ndf.info() # get information about DataFrame\ndf.describe() # get summary statistics for numeric columns\ndf.sort_values('duration_ms', ascending=True) # sort DataFrame by column\ndf.drop('duration_ms', axis=1) # remove a column\ndf.drop_duplicates() # remove duplicate rows"},"id":"169b3b1e-1ac0-4df4-a13b-a004fed8bdbb","cell_type":"code","execution_count":41,"outputs":[]},{"source":"## Indexing and selection","metadata":{},"id":"05b9e9a5-8a19-441b-96b1-d5df92fae374","cell_type":"markdown"},{"source":"df['duration_ms'] # select a single column by name\ndf[['duration_ms', 'loudness']] # select multiple columns by name\ndf.iloc[4, 5] # select data by integer location\n#df.loc['Eggs'] # select data by label\n#df.query('popularity') # select data by condition","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"executionTime":24,"lastSuccessfullyExecutedCode":"df['duration_ms'] # select a single column by name\ndf[['duration_ms', 'loudness']] # select multiple columns by name\ndf.iloc[4, 5] # select data by integer location\n#df.loc['Eggs'] # select data by label\n#df.query('popularity') # select data by condition"},"id":"1d71ab08-ab71-4c4a-b49b-ddd3b50b1404","cell_type":"code","execution_count":42,"outputs":[]},{"source":"## Data cleaning","metadata":{},"id":"78aeb9c8-4ff5-457d-b1db-94fb0c45b856","cell_type":"markdown"},{"source":"df.isnull() # check for missing values\ndf.fillna(0) # fill missing values with a given value\ndf.dropna() # drop rows with missing values\ndf.replace(\"a\", \"b\") # replace values in DataFrame\ndf.apply(lambda x: x+1) # apply a function to each row or column\ndf.rename(columns={'old_name': 'new_name'}) # rename columns\ndf[\"energy\"].astype(\"int\") # change column data type","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"executionTime":41,"lastSuccessfullyExecutedCode":"df.isnull() # check for missing values\ndf.fillna(0) # fill missing values with a given value\ndf.dropna() # drop rows with missing values\ndf.replace(\"a\", \"b\") # replace values in DataFrame\ndf.apply(lambda x: x+1) # apply a function to each row or column\ndf.rename(columns={'old_name': 'new_name'}) # rename columns\ndf[\"energy\"].astype(\"int\") # change column data type"},"id":"e6d4a1a4-9812-4908-b0e8-6ef3fe2d74cf","cell_type":"code","execution_count":43,"outputs":[]},{"source":"## Grouping and aggregation","metadata":{},"id":"0ea94bac-d128-4158-b01c-06d56ee2b0fe","cell_type":"markdown"},{"source":"df.groupby('genre').mean() # group by column and get mean of each group\ndf.groupby(['genre', 'danceability']).agg(['mean', 'median', 'max']) # group by multiple columns and get multiple aggregations\ndf.pivot_table(values='duration_ms', index='danceability', columns='genre', aggfunc='mean') # create a pivot table","metadata":{"executionTime":24,"lastSuccessfullyExecutedCode":"df.groupby('genre').mean() # group by column and get mean of each group\ndf.groupby(['genre', 'danceability']).agg(['mean', 'median', 'max']) # group by multiple columns and get multiple aggregations\ndf.pivot_table(values='duration_ms', index='danceability', columns='genre', aggfunc='mean') # create a pivot table"},"id":"6cb83684-8fcc-4a46-b087-0b1cfe05e877","cell_type":"code","execution_count":44,"outputs":[]},{"source":"## Merging and joining","metadata":{},"id":"b6c2028c-5cfd-492e-b4eb-21795a647aa3","cell_type":"markdown"},{"source":"#df1.merge(df2, on='column_name') # merge two DataFrames by a shared column\n#df1.join(df2, how='inner') # join two DataFrames by index","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"#df1.merge(df2, on='column_name') # merge two DataFrames by a shared column\n#df1.join(df2, how='inner') # join two DataFrames by index"},"id":"60542967-0626-4c82-a2e8-d3683fea00bf","cell_type":"code","execution_count":45,"outputs":[]},{"source":"## Exporting data","metadata":{},"id":"6bc256d7-c059-4d6a-8edc-ecf106e86ad2","cell_type":"markdown"},{"source":"df.to_csv('filename.csv', index=False) # export DataFrame to CSV file\ndf.to_excel('filename.xlsx', index=False) # export DataFrame to Excel file\n#df.to_sql('table_name', connection) # export DataFrame to SQL database","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"df.to_csv('filename.csv', index=False) # export DataFrame to CSV file\ndf.to_excel('filename.xlsx', index=False) # export DataFrame to Excel file\n#df.to_sql('table_name', connection) # export DataFrame to SQL database"},"id":"a61d9fc3-dcc5-4356-93ad-af2d320a4536","cell_type":"code","execution_count":46,"outputs":[]},{"source":"# Going into details...","metadata":{},"id":"88a8b3c2-ddfd-401b-97f1-4c0ca72e81a3","cell_type":"markdown"},{"source":"pandas.**dropna()** is a function in the Pandas library of Python used to remove missing or null values from a DataFrame or a Series. ","metadata":{},"id":"e508602b-b0a2-411c-9d70-6f970d72797d","cell_type":"markdown"},{"source":"- axis: It specifies the axis along which the null values are to be dropped. By default, it is set to 0 which means it drops the rows containing null values.\n- how: It specifies the condition for dropping the rows or columns. It takes two values: 'any' or 'all'. 'any' means that it drops the row or column if there is at least one null value in it. 'all' means it drops the row or column if all the values in it are null.\n- thresh: It is the minimum number of non-null values required to keep the row or column. If the number of non-null values in the row or column is less than this threshold value, it will be dropped.\n- subset: It specifies the columns or rows from which the null values are to be dropped.\n- inplace: It is a boolean value that specifies whether to modify the DataFrame in place or return a new DataFrame without null values.","metadata":{},"id":"0f87461f-e884-49ee-bbf6-ccbf7b1095a6","cell_type":"markdown"},{"source":"import pandas as pd\n\n# Creating a DataFrame with missing values\ndf = pd.DataFrame({'A': [1, 2, None, 4],\n                   'B': [5, None, None, 8],\n                   'C': [9, 10, 11, 12]})\n\n# Dropping the rows with null values\ndf.dropna(inplace=True, how='any')\nprint(df)","metadata":{"executionTime":13,"lastSuccessfullyExecutedCode":"import pandas as pd\n\n# Creating a DataFrame with missing values\ndf = pd.DataFrame({'A': [1, 2, None, 4],\n                   'B': [5, None, None, 8],\n                   'C': [9, 10, 11, 12]})\n\n# Dropping the rows with null values\ndf.dropna(inplace=True, how='any')\nprint(df)"},"id":"a57ed47f-a5a6-4ec7-8d95-08a124a2f104","cell_type":"code","execution_count":47,"outputs":[]},{"source":"fillna is a method in pandas that allows us to fill missing values in a DataFrame or a Series. Here are some of its most common parameters:\n\n- value: This parameter specifies the value to use for filling missing values.\n- method: This parameter specifies the method to use for filling missing values. For example, we can use \"ffill\" to fill missing values with the previous non-missing value, or \"bfill\" to fill missing values with the next non-missing value.\n- axis: This parameter specifies the axis along which to fill missing values. By default, it is set to 0, which means that missing values are filled vertically, column by column. If it is set to 1, missing values are filled horizontally, row by row.\n- inplace: This parameter specifies whether to modify the DataFrame or Series in place or return a new one with the missing values filled. By default, it is set to False, which means that a new DataFrame or Series is returned. If it is set to True, the original DataFrame or Series is modified in place.","metadata":{},"id":"eb579ca2-4c48-4143-ac23-8f1313a02133","cell_type":"markdown"},{"source":"import pandas as pd\nimport numpy as np\n\n# create a Series with missing values\ns = pd.Series([1, 2, np.nan, 4, np.nan, 6])\n\n# fill missing values with the mean\ns = s.fillna(method='ffill')\n\nprint(s)","metadata":{"executionTime":12,"lastSuccessfullyExecutedCode":"import pandas as pd\nimport numpy as np\n\n# create a Series with missing values\ns = pd.Series([1, 2, np.nan, 4, np.nan, 6])\n\n# fill missing values with the mean\ns = s.fillna(method='ffill')\n\nprint(s)"},"id":"9b5f0981-5b3e-468b-bcac-5ac12441a1f0","cell_type":"code","execution_count":48,"outputs":[]},{"source":"**melt()** is a function in the Pandas library that helps to transform or reshape a dataframe from a wide format to a long format. It takes a dataframe as input and unpivots it into a more normalized form suitable for data analysis or visualization.\n\nThe melt() function pivots the DataFrame from a wide format to a long format by \"melting\" or unpivoting selected columns into rows, while keeping all the other columns fixed.\n\nThe main parameters for the melt() function are:\n- \n- id_vars: The column(s) that will remain the same and will not be melted.\n- value_vars: The column(s) to be melted.\n- var_name: The name of the column to be created for the melted columns.\n- value_name: The name of the column to be created for the values of the melted columns.","metadata":{},"id":"10688449-b5ba-4af8-b8f3-a933a2dc42ec","cell_type":"markdown"},{"source":"import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Bob', 'Sue', 'John'],\n    'math': [80, 90, 70],\n    'physics': [75, 85, 80],\n    'chemistry': [85, 90, 75]\n})\n\nlong_df = pd.melt(df, id_vars=['name'], value_vars=['math', 'physics', 'chemistry'], var_name='subject', value_name='score')\n\nprint(long_df)","metadata":{"executionTime":16,"lastSuccessfullyExecutedCode":"import pandas as pd\n\ndf = pd.DataFrame({\n    'name': ['Bob', 'Sue', 'John'],\n    'math': [80, 90, 70],\n    'physics': [75, 85, 80],\n    'chemistry': [85, 90, 75]\n})\n\nlong_df = pd.melt(df, id_vars=['name'], value_vars=['math', 'physics', 'chemistry'], var_name='subject', value_name='score')\n\nprint(long_df)"},"id":"2a62059f-101b-481a-a933-0ae7e8bb9a74","cell_type":"code","execution_count":49,"outputs":[]},{"source":"**pandas.read_excel()** is a function that reads data from an Excel file into a pandas DataFrame. It has many optional parameters that can be used to customize how the Excel file is read.\n\nHere are some of the important parameters:\n\n- io: Required parameter. The Excel file to read from, specified as a string or a file-like object.\n- sheet_name: The sheet(s) to read from the Excel file. Can be specified as a string or an integer (for sheet index), a list of strings/integers or None (for all sheets).\n- header: The row number(s) to use as the column names. By default, it is the first row.\n- names: List of column names to use instead of the header row(s).\n- index_col: Column(s) to use as the row labels of the DataFrame.\n- usecols: Columns to read from the Excel file. Can be specified as a string (e.g. \"A:C\"), a list of strings (e.g. [\"A\", \"C\", \"D\"]), or a range (e.g. \"A:D\").\n- skiprows: Number of rows to skip from the beginning of the Excel file.\n- skipfooter: Number of rows to skip from the end of the Excel file.\n- nrows: Number of rows to read from the Excel file.\n- dtype: Data type for one or more columns.\n- na_values: Values to consider as missing values.\n- parse_dates: Columns to parse as dates.\n- date_parser: Function to use to parse dates.\n- keep_default_na: Whether or not to keep the default NaN values when parsing the Excel file.\n- thousands: Separator to use for thousands (e.g. ',' or '.').\n- decimal: Separator to use for decimal points (e.g. ',' or '.').\n- engine: The parsing engine to use. Can be \"xlrd\" (default), \"openpyxl\", or \"odf\".","metadata":{},"id":"c43f3663-1a42-49ef-a625-d4390d79b9a7","cell_type":"markdown"}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}